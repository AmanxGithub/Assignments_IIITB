{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "    1. Submit your python notebooks in zip format with naming convention as:\n",
    "        \n",
    "            RollNo1_RollNo2_RollNo3.zip\n",
    "            \n",
    "    2. Cheating of any form will not be tolerated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill your Team details here.<br>\n",
    "<br>\n",
    "Format: Roll Number\n",
    " \n",
    "         1.MT2018090\n",
    "         2.MT2018116\n",
    "         3.MT2018026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: You need to build Logistic Regression from scratch using training set of Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions for each cell are provided, along with the marks they hold. Fill in the cells with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/shuvambosana/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed value to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed value to 100.\n",
    "np.random.seed(100)\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"train.csv\" dataset. You will be using the same file for sampling training and testing points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train.csv dataset\n",
    "data=pd.read_csv(\"train.csv\")\n",
    "data.shape\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all missing rows and columns from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use dropna() to remove null values from data\n",
    "newData=data.dropna()\n",
    "newData.shape\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select following features from dataset. <br>\n",
    "\n",
    "        1. Sex\n",
    "        2. Age\n",
    "        3. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 183 entries, 1 to 889\n",
      "Data columns (total 3 columns):\n",
      "Survived    183 non-null int64\n",
      "Sex         183 non-null object\n",
      "Age         183 non-null float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 5.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Select Sex, Age, Survived columns.\n",
    "finalData=newData.drop(['PassengerId', 'Pclass', 'Name', 'SibSp',\n",
    "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],axis=1)\n",
    "finalData.info()\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable to be predicted is whether a person will \"survive\" the Titanic tragedy or not.\n",
    "\n",
    "Store the target 'Survived' in 'y' variable and other variables in 'X'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 'Survived' in y variable and other variables in X.\n",
    "X = finalData.drop(['Survived'],axis=1)\n",
    "y = finalData['Survived']\n",
    "# X.info()\n",
    "# y\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the 'Sex' column are 'Male/Female'. So convert them into 1/0 using Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X['Sex'] = le.fit_transform(finalData.Sex) \n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0\n",
       "3      0\n",
       "6      1\n",
       "10     0\n",
       "11     0\n",
       "21     1\n",
       "23     1\n",
       "27     1\n",
       "52     0\n",
       "54     1\n",
       "62     1\n",
       "66     0\n",
       "75     1\n",
       "88     0\n",
       "92     1\n",
       "96     1\n",
       "97     1\n",
       "102    1\n",
       "110    1\n",
       "118    1\n",
       "123    0\n",
       "124    1\n",
       "136    0\n",
       "137    1\n",
       "139    1\n",
       "148    1\n",
       "151    0\n",
       "170    1\n",
       "174    1\n",
       "177    0\n",
       "      ..\n",
       "737    1\n",
       "741    1\n",
       "742    0\n",
       "745    1\n",
       "748    1\n",
       "751    1\n",
       "759    0\n",
       "763    0\n",
       "765    0\n",
       "772    0\n",
       "779    0\n",
       "781    0\n",
       "782    1\n",
       "789    1\n",
       "796    0\n",
       "802    1\n",
       "806    1\n",
       "809    0\n",
       "820    0\n",
       "823    0\n",
       "835    0\n",
       "853    0\n",
       "857    1\n",
       "862    0\n",
       "867    1\n",
       "871    0\n",
       "872    1\n",
       "879    0\n",
       "887    0\n",
       "889    1\n",
       "Name: Sex, Length: 183, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test with a test size of 20% of total dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x_=np.array(X_train)\n",
    "_x_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert X_train, y_train, X_test, y_test into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sigmoid function. <br>\n",
    "        \n",
    "           1. Input: An array.\n",
    "           2. Output: Sigmoid of Input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1/(1+np.exp((-1)*z)))\n",
    "    \n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73105858 0.73105858]\n"
     ]
    }
   ],
   "source": [
    "a=np.ones(2)\n",
    "print(sigmoid(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,\n",
       "         1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  1.  ,  0.  ,\n",
       "         1.  ,  0.  ,  1.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,\n",
       "         1.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,\n",
       "         1.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,\n",
       "         1.  ,  1.  ,  0.  ,  0.  ,  1.  ,  1.  ,  1.  ,  0.  ,  0.  ,\n",
       "         1.  ,  0.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.  ,\n",
       "         0.  ,  0.  ,  1.  ,  1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,\n",
       "         1.  ,  0.  ],\n",
       "       [32.  , 18.  , 57.  , 48.  , 52.  , 50.  , 24.  , 49.  , 45.  ,\n",
       "        35.  , 27.  , 30.  , 50.  , 58.  , 19.  , 47.  , 54.  , 48.  ,\n",
       "        22.  , 35.  , 25.  , 58.  , 36.  , 56.  , 38.  , 19.  , 45.  ,\n",
       "        18.  , 25.  , 44.  , 23.  , 48.  , 43.  , 52.  , 47.  , 31.  ,\n",
       "        39.  , 52.  , 11.  , 17.  , 33.  , 56.  , 30.  ,  4.  , 24.  ,\n",
       "        54.  , 27.  , 54.  ,  2.  , 14.  , 31.  , 28.  , 33.  , 38.  ,\n",
       "        38.  , 27.  , 45.5 ,  0.92, 30.  , 52.  , 39.  , 40.  , 36.  ,\n",
       "        60.  , 48.  , 42.  , 49.  , 42.  , 48.  , 39.  , 45.  ,  2.  ,\n",
       "        44.  , 27.  , 38.  , 28.  , 29.  , 26.  , 61.  , 25.  , 37.  ,\n",
       "        36.  , 29.  , 65.  , 21.  , 47.  , 51.  , 33.  ,  6.  ,  4.  ,\n",
       "        55.  , 50.  , 27.  , 16.  , 71.  , 37.  , 19.  , 22.  , 24.  ,\n",
       "        36.  , 22.  , 25.  , 62.  , 24.  ,  4.  , 36.  , 37.  , 24.  ,\n",
       "        16.  ,  1.  , 60.  , 53.  , 36.  , 49.  , 31.  , 21.  , 35.  ,\n",
       "        30.  , 19.  , 40.  , 36.  , 19.  , 33.  , 49.  , 64.  , 35.  ,\n",
       "        41.  , 63.  , 42.  , 19.  , 70.  , 15.  , 24.  , 16.  , 32.5 ,\n",
       "        36.5 , 58.  , 24.  , 80.  , 35.  , 23.  , 56.  , 36.  , 24.  ,\n",
       "        31.  , 32.  ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function for logistic regression.\n",
    "\n",
    "y is the label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "#     _loss=[]\n",
    "#     size=y_train.size\n",
    "#     j=0\n",
    "#     for i in y:\n",
    "#         _loss.append(i*log(h[j])+(1-i)*log(1-h[j]))\n",
    "#         j+=1\n",
    "    return (y*np.log(h)+(1-y)*np.log(1-h))\n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class for Logistic Regression function. <br>\n",
    "\n",
    "            Input X, y, NumberOfIterations, LearningRate.\n",
    "            Output: Updated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (146,) (146,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-15dcf494cd42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-924bf6b2614a>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(h, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         _loss.append(i*log(h[j])+(1-i)*log(1-h[j]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         j+=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# 3 Marks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (146,) (146,2) "
     ]
    }
   ],
   "source": [
    "b=loss(X_train,y_train)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression(X, y, NumberOfIterations, LearningRate):        \n",
    "   \n",
    "    # Initialize weights randomly\n",
    "    weights = np.array([np.random.rand(1),np.random.rand(1),np.random.rand(1)])\n",
    "    X_transpose=np.transpose(X)\n",
    "    for i in range(NumberOfIterations):\n",
    "            \n",
    "        # Forward pass\n",
    "        Z = weights[0]+weights[1]*X_transpose[0]+weights[2]*X_transpose[1]\n",
    "        A = sigmoid(Z)\n",
    "\n",
    "        # Loss Computation\n",
    "        J = loss(A, y)\n",
    "\n",
    "        # Gradient computation\n",
    "        dZ = A - y\n",
    "        dweights = LearningRate*weights\n",
    "\n",
    "        # Update weights\n",
    "        weights = (-1)*dweights\n",
    "            \n",
    "        # Printing loss after every 100 iterations\n",
    "        if(i % 100 == 0):\n",
    "            print('loss:' + str(J) + '\\t')\n",
    "    return weights\n",
    "\n",
    "# 8 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define prediction function. <br>\n",
    "\n",
    "        Input: X, threshold, weights.\n",
    "        Output: Corresponding labels for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold, weights):\n",
    "    X_test_tr=np.transpose(X)\n",
    "    _y=weights[0]+weights[1]*X_test_tr[0]+weights[2]*X_test_tr[1]\n",
    "    pr=sigmoid(_y)\n",
    "    print(pr)\n",
    "    res=[]\n",
    "    for i in pr:\n",
    "        if(i>=threshold):\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return res\n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LogisticRegression function with following inputs to train on training set.\n",
    "\n",
    "    1. X_train\n",
    "    2. y_train\n",
    "    3. NumberOfIterations = 1000\n",
    "    4. LearningRate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call  LogisticRegression function and store weights in model.\n",
    "NumberOfIterations=1000\n",
    "LearningRate=0.1\n",
    "model = LogisticRegression(X_train,y_train,NumberOfIterations,LearningRate)\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on testing data. Store predictions in preds variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in preds variable.\n",
    "threshold = 0.5\n",
    "preds = predict(X_test,threshold,model)\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy on test dataset given y_test (in the beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "total=0\n",
    "for i,j in y_test,preds:\n",
    "    total+=1\n",
    "    if(i==j):\n",
    "        count+=1\n",
    "\n",
    "Accuracy = (count*100)/total\n",
    "Accuracy\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the reason behind such low accuracy? What do you think are possible ways of improving it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Marks for answering above question. Type out the answer below.\n",
    "The reason for such a low accuracy is that we have discarded most of the attributes without suitable exploration of \n",
    "how it is correlated with the predication value,i.e.,'Survived' feature. Moreover due to discarding all the null values, \n",
    "our dataset has shrunk to almost one-third. So instead of dropping those values, we should have replaced it with suitable \n",
    "values rather than plainly discarding it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type Here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROC Curve for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 5 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
