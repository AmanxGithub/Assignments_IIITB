{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "    1. Submit your python notebooks in zip format with naming convention as:\n",
    "        \n",
    "            RollNo1_RollNo2_RollNo3.zip\n",
    "            \n",
    "    2. Cheating of any form will not be tolerated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill your Team details here.<br>\n",
    "<br>\n",
    "Format: Roll Number\n",
    " \n",
    "         1.\n",
    "         2.\n",
    "         3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: You need to build Logistic Regression from scratch using training set of Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions for each cell are provided, along with the marks they hold. Fill in the cells with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed value to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed value to 100.\n",
    "np.random.seed(100)\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"train.csv\" dataset. You will be using the same file for sampling training and testing points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train.csv dataset\n",
    "\n",
    "data =pd.read_csv(\"train.csv\")\n",
    "\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all missing rows and columns from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dropna() to remove null values from data\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select following features from dataset. <br>\n",
    "\n",
    "        1. Sex\n",
    "        2. Age\n",
    "        3. Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Sex, Age, Survived columns.\n",
    "\n",
    "data  = data[['Sex','Age','Survived']]\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable to be predicted is whether a person will \"survive\" the Titanic tragedy or not.\n",
    "\n",
    "Store the target 'Survived' in 'y' variable and other variables in 'X'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 'Survived' in y variable and other variables in X.\n",
    "y = data['Survived']\n",
    "data.drop(['Survived'],axis=1,inplace = True)\n",
    "X = data\n",
    "\n",
    "\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the 'Sex' column are 'Male/Female'. So convert them into 1/0 using Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LabelEncoder()\n",
    "\n",
    "X['Sex'] = l.fit_transform(X.Sex)\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test with a test size of 20% of total dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.4)\n",
    "\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert X_train, y_train, X_test, y_test into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sigmoid function. <br>\n",
    "        \n",
    "           1. Input: An array.\n",
    "           2. Output: Sigmoid of Input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1/(1 + np.exp(-z)))\n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function for logistic regression.\n",
    "\n",
    "y is the label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "    return np.mean((-1)*(y.T.dot(np.log(h))+(1-(y.T)).dot(np.log(1-h))))\n",
    "\n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class for Logistic Regression function. <br>\n",
    "\n",
    "            Input X, y, NumberOfIterations, LearningRate.\n",
    "            Output: Updated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression(X, y, NumberOfIterations, threshold , LearningRate):        \n",
    "   \n",
    "    # Initialize weights randomly\n",
    "    weights = np.array([np.random.rand(1),np.random.rand(1),np.random.rand(1)])\n",
    "\n",
    "    for i in range(NumberOfIterations):\n",
    "\n",
    "        Z = np.dot(X,weights)\n",
    "        A = sigmoid(Z)\n",
    "        map(lambda x : 1 if x>=threshold else 0,A)\n",
    "        \n",
    "        # Loss Computation\n",
    "        J = loss(A, y)\n",
    "        \n",
    "        # Gradient computation\n",
    "        dZ = (np.dot(X.T,(A - y)) / y.shape[0])\n",
    "        dweights = LearningRate * dZ\n",
    "\n",
    "        # Update weights\n",
    "        weights = weights - dweights\n",
    "\n",
    "        # Printing loss after every 100 iterations\n",
    "        if(i % 100 == 0):\n",
    "            print('loss:' + str(J) + '\\t')\n",
    "            \n",
    "    return weights\n",
    "# 8 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define prediction function. <br>\n",
    "\n",
    "        Input: X, threshold, weights.\n",
    "        Output: Corresponding labels for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold, weights):\n",
    "    _y = np.dot(X,weights)\n",
    "    pr=np.array(sigmoid(_y))\n",
    "    res =[]\n",
    "    for i in pr:\n",
    "        if i>threshold:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return res\n",
    "    \n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LogisticRegression function with following inputs to train on training set.\n",
    "\n",
    "    1. X_train\n",
    "    2. y_train\n",
    "    3. NumberOfIterations = 1000\n",
    "    4. LearningRate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (109,2) and (3,1) not aligned: 2 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-05e583ef3914>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mNumberOfIterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLearningRate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNumberOfIterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLearningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-9261809a77f8>\u001b[0m in \u001b[0;36mLogisticRegression\u001b[0;34m(X, y, NumberOfIterations, threshold, LearningRate)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNumberOfIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (109,2) and (3,1) not aligned: 2 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Call  LogisticRegression function and store weights in model.\n",
    "NumberOfIterations=1000\n",
    "LearningRate=0.1\n",
    "model = LogisticRegression(X_train,y_train,NumberOfIterations,0.5,LearningRate)\n",
    "print(model)\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on testing data. Store predictions in preds variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in preds variable.\n",
    "threshold = 0.5\n",
    "preds = predict(X_test,threshold,model)\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy on test dataset given y_test (in the beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(y_test.shape[0]):\n",
    "    if (y_test[i] == preds[i]):\n",
    "        c+=1;\n",
    "Accuracy = (c*100)/y_test.shape[0]\n",
    "Accuracy\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the reason behind such low accuracy? What do you think are possible ways of improving it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Marks for answering above question. Type out the answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for such a low accuracy is that we have discarded most of the attributes without suitable exploration of \n",
    "how it is correlated with the predication value,i.e.,'Survived' feature. Moreover due to discarding all the null values, \n",
    "our dataset has shrunk to almost one-third. So instead of dropping those values, we should have replaced it with suitable \n",
    "values rather than plainly discarding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROC Curve for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 5 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
