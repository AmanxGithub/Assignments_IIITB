{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "    1. Submit your python notebooks in zip format with naming convention as:\n",
    "        \n",
    "            RollNo1_RollNo2_RollNo3.zip\n",
    "            \n",
    "    2. Cheating of any form will not be tolerated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill your Team details here.<br>\n",
    "<br>\n",
    "Format: Roll Number\n",
    " \n",
    "         1.MT2018090\n",
    "         2.MT2018116\n",
    "         3.MT2018026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: You need to build Logistic Regression from scratch using training set of Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions for each cell are provided, along with the marks they hold. Fill in the cells with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed value to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed value to 100.\n",
    "np.random.seed(100)\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"train.csv\" dataset. You will be using the same file for sampling training and testing points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train.csv dataset\n",
    "data=pd.read_csv(\"train.csv\")\n",
    "data.shape\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all missing rows and columns from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use dropna() to remove null values from data\n",
    "newData=data.dropna()\n",
    "newData.shape\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select following features from dataset. <br>\n",
    "\n",
    "        1. Sex\n",
    "        2. Age\n",
    "        3. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 183 entries, 1 to 889\n",
      "Data columns (total 3 columns):\n",
      "Survived    183 non-null int64\n",
      "Sex         183 non-null object\n",
      "Age         183 non-null float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 5.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Select Sex, Age, Survived columns.\n",
    "finalData=newData.drop(['PassengerId', 'Pclass', 'Name', 'SibSp',\n",
    "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],axis=1)\n",
    "finalData.info()\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable to be predicted is whether a person will \"survive\" the Titanic tragedy or not.\n",
    "\n",
    "Store the target 'Survived' in 'y' variable and other variables in 'X'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 183 entries, 1 to 889\n",
      "Data columns (total 2 columns):\n",
      "Sex    183 non-null object\n",
      "Age    183 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1      1\n",
       "3      1\n",
       "6      0\n",
       "10     1\n",
       "11     1\n",
       "21     1\n",
       "23     1\n",
       "27     0\n",
       "52     1\n",
       "54     0\n",
       "62     0\n",
       "66     1\n",
       "75     0\n",
       "88     1\n",
       "92     0\n",
       "96     0\n",
       "97     1\n",
       "102    0\n",
       "110    0\n",
       "118    0\n",
       "123    1\n",
       "124    0\n",
       "136    1\n",
       "137    0\n",
       "139    0\n",
       "148    0\n",
       "151    1\n",
       "170    0\n",
       "174    0\n",
       "177    0\n",
       "      ..\n",
       "737    1\n",
       "741    0\n",
       "742    1\n",
       "745    0\n",
       "748    0\n",
       "751    1\n",
       "759    1\n",
       "763    1\n",
       "765    1\n",
       "772    0\n",
       "779    1\n",
       "781    1\n",
       "782    0\n",
       "789    0\n",
       "796    1\n",
       "802    1\n",
       "806    0\n",
       "809    1\n",
       "820    1\n",
       "823    1\n",
       "835    1\n",
       "853    1\n",
       "857    1\n",
       "862    1\n",
       "867    0\n",
       "871    1\n",
       "872    0\n",
       "879    1\n",
       "887    1\n",
       "889    1\n",
       "Name: Survived, Length: 183, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store 'Survived' in y variable and other variables in X.\n",
    "X = finalData.drop(['Survived'],axis=1)\n",
    "y = finalData['Survived']\n",
    "# X.info()\n",
    "# y\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the 'Sex' column are 'Male/Female'. So convert them into 1/0 using Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X['Sex'] = le.fit_transform(finalData.Sex) \n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0\n",
       "3      0\n",
       "6      1\n",
       "10     0\n",
       "11     0\n",
       "21     1\n",
       "23     1\n",
       "27     1\n",
       "52     0\n",
       "54     1\n",
       "62     1\n",
       "66     0\n",
       "75     1\n",
       "88     0\n",
       "92     1\n",
       "96     1\n",
       "97     1\n",
       "102    1\n",
       "110    1\n",
       "118    1\n",
       "123    0\n",
       "124    1\n",
       "136    0\n",
       "137    1\n",
       "139    1\n",
       "148    1\n",
       "151    0\n",
       "170    1\n",
       "174    1\n",
       "177    0\n",
       "      ..\n",
       "737    1\n",
       "741    1\n",
       "742    0\n",
       "745    1\n",
       "748    1\n",
       "751    1\n",
       "759    0\n",
       "763    0\n",
       "765    0\n",
       "772    0\n",
       "779    0\n",
       "781    0\n",
       "782    1\n",
       "789    1\n",
       "796    0\n",
       "802    1\n",
       "806    1\n",
       "809    0\n",
       "820    0\n",
       "823    0\n",
       "835    0\n",
       "853    0\n",
       "857    1\n",
       "862    0\n",
       "867    1\n",
       "871    0\n",
       "872    1\n",
       "879    0\n",
       "887    0\n",
       "889    1\n",
       "Name: Sex, Length: 183, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test with a test size of 20% of total dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x_=np.array(X_train)\n",
    "_x_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert X_train, y_train, X_test, y_test into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sigmoid function. <br>\n",
    "        \n",
    "           1. Input: An array.\n",
    "           2. Output: Sigmoid of Input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1/(1+np.exp((-1)*z)))\n",
    "    \n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73105858 0.73105858]\n"
     ]
    }
   ],
   "source": [
    "a=np.ones(2)\n",
    "print(sigmoid(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,\n",
       "         1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  1.  ,  0.  ,\n",
       "         1.  ,  0.  ,  1.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,\n",
       "         1.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,\n",
       "         1.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,\n",
       "         1.  ,  1.  ,  0.  ,  0.  ,  1.  ,  1.  ,  1.  ,  0.  ,  0.  ,\n",
       "         1.  ,  0.  ,  1.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.  ,\n",
       "         0.  ,  0.  ,  1.  ,  1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,  1.  ,  1.  ,  0.  ,\n",
       "         1.  ,  0.  ],\n",
       "       [32.  , 18.  , 57.  , 48.  , 52.  , 50.  , 24.  , 49.  , 45.  ,\n",
       "        35.  , 27.  , 30.  , 50.  , 58.  , 19.  , 47.  , 54.  , 48.  ,\n",
       "        22.  , 35.  , 25.  , 58.  , 36.  , 56.  , 38.  , 19.  , 45.  ,\n",
       "        18.  , 25.  , 44.  , 23.  , 48.  , 43.  , 52.  , 47.  , 31.  ,\n",
       "        39.  , 52.  , 11.  , 17.  , 33.  , 56.  , 30.  ,  4.  , 24.  ,\n",
       "        54.  , 27.  , 54.  ,  2.  , 14.  , 31.  , 28.  , 33.  , 38.  ,\n",
       "        38.  , 27.  , 45.5 ,  0.92, 30.  , 52.  , 39.  , 40.  , 36.  ,\n",
       "        60.  , 48.  , 42.  , 49.  , 42.  , 48.  , 39.  , 45.  ,  2.  ,\n",
       "        44.  , 27.  , 38.  , 28.  , 29.  , 26.  , 61.  , 25.  , 37.  ,\n",
       "        36.  , 29.  , 65.  , 21.  , 47.  , 51.  , 33.  ,  6.  ,  4.  ,\n",
       "        55.  , 50.  , 27.  , 16.  , 71.  , 37.  , 19.  , 22.  , 24.  ,\n",
       "        36.  , 22.  , 25.  , 62.  , 24.  ,  4.  , 36.  , 37.  , 24.  ,\n",
       "        16.  ,  1.  , 60.  , 53.  , 36.  , 49.  , 31.  , 21.  , 35.  ,\n",
       "        30.  , 19.  , 40.  , 36.  , 19.  , 33.  , 49.  , 64.  , 35.  ,\n",
       "        41.  , 63.  , 42.  , 19.  , 70.  , 15.  , 24.  , 16.  , 32.5 ,\n",
       "        36.5 , 58.  , 24.  , 80.  , 35.  , 23.  , 56.  , 36.  , 24.  ,\n",
       "        31.  , 32.  ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function for logistic regression.\n",
    "\n",
    "y is the label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "#     _loss=[]\n",
    "#     size=y_train.size\n",
    "#     j=0\n",
    "#     for i in y:\n",
    "#         _loss.append(i*log(h[j])+(1-i)*log(1-h[j]))\n",
    "#         j+=1\n",
    "    return (y*np.log(h)++(1-y)*np.log(1-h))\n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class for Logistic Regression function. <br>\n",
    "\n",
    "            Input X, y, NumberOfIterations, LearningRate.\n",
    "            Output: Updated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (146,) (146,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-15dcf494cd42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-423844fcc88b>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(h, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         _loss.append(i*log(h[j])+(1-i)*log(1-h[j]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         j+=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# 3 Marks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (146,) (146,2) "
     ]
    }
   ],
   "source": [
    "b=loss(X_train,y_train)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression(X, y, NumberOfIterations, LearningRate):        \n",
    "   \n",
    "    # Initialize weights randomly\n",
    "    weights = np.array([np.random.rand(1),np.random.rand(1),np.random.rand(1)])\n",
    "    X_transpose=np.transpose(X)\n",
    "    for i in range(NumberOfIterations):\n",
    "            \n",
    "        # Forward pass\n",
    "        Z = weights[0]+weights[1]*X_transpose[0]+weights[2]*X_transpose[1]\n",
    "        A = sigmoid(Z)\n",
    "\n",
    "        # Loss Computation\n",
    "        J = loss(A, y)\n",
    "\n",
    "        # Gradient computation\n",
    "        dZ = A - y\n",
    "        dweights = LearningRate*weights\n",
    "\n",
    "        # Update weights\n",
    "        weights = (-1)*dweights\n",
    "            \n",
    "        # Printing loss after every 100 iterations\n",
    "        if(i % 100 == 0):\n",
    "            print('loss:' + str(J) + '\\t')\n",
    "    return weights\n",
    "\n",
    "# 8 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define prediction function. <br>\n",
    "\n",
    "        Input: X, threshold, weights.\n",
    "        Output: Corresponding labels for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold, weights):\n",
    "    X_test_tr=np.transpose(X)\n",
    "    _y=weights[0]+weights[1]*X_test_tr[0]+weights[2]*X_test_tr[1]\n",
    "    pr=sigmoid(_y)\n",
    "    print(pr)\n",
    "    res=[]\n",
    "    for i in pr:\n",
    "        if(i>=threshold):\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return res\n",
    "# 3 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LogisticRegression function with following inputs to train on training set.\n",
    "\n",
    "    1. X_train\n",
    "    2. y_train\n",
    "    3. NumberOfIterations = 1000\n",
    "    4. LearningRate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:[-8.70322509e-03 -4.70457199e-02 -7.77463637e+00 -1.24896842e-03\n",
      " -7.71822197e-04 -9.84157817e-04 -2.29614689e-02 -1.11130669e-03\n",
      " -6.32190356e+00 -6.08008294e-03 -1.59254860e-02 -1.11376530e-02\n",
      " -6.92893055e+00 -3.72240181e-04 -4.17712182e-02 -6.56465397e+00\n",
      " -6.05284894e-04 -1.24896842e-03 -2.91900519e-02 -6.05154593e-03\n",
      " -3.90898776e+00 -7.90087448e+00 -5.36067771e-03 -7.65783819e+00\n",
      " -5.47332765e+00 -4.17712182e-02 -6.32190356e+00 -3.08456851e+00\n",
      " -2.02647472e-02 -2.03993448e-03 -2.58915245e-02 -1.25487234e-03\n",
      " -2.30332808e-03 -7.17185746e+00 -6.56465397e+00 -9.86899325e-03\n",
      " -5.59441620e+00 -7.71822197e-04 -1.06412388e-01 -5.27258825e-02\n",
      " -7.74712724e-03 -4.74673081e-04 -4.50765412e+00 -2.34438732e-01\n",
      " -2.29614689e-02 -7.41482995e+00 -1.59254860e-02 -7.41482995e+00\n",
      " -2.89180192e-01 -7.54194165e-02 -4.62796049e+00 -1.41152950e-02\n",
      " -7.74712724e-03 -4.22592786e-03 -4.22592786e-03 -4.14778674e+00\n",
      " -6.38258217e+00 -3.23807155e-01 -1.11376530e-02 -7.68190054e-04\n",
      " -3.74308938e-03 -5.71555956e+00 -5.38596560e-03 -2.91908740e-04\n",
      " -1.24896842e-03 -2.58845898e-03 -1.10607784e-03 -2.58845898e-03\n",
      " -1.25487234e-03 -3.74308938e-03 -6.32190356e+00 -1.37828167e+00\n",
      " -2.03993448e-03 -1.60002142e-02 -4.20607507e-03 -1.41152950e-02\n",
      " -4.38750907e+00 -1.79657439e-02 -8.26546864e+00 -3.90436378e+00\n",
      " -5.35230095e+00 -5.36067771e-03 -4.38750907e+00 -8.75164605e+00\n",
      " -3.29019372e-02 -6.56465397e+00 -8.67448942e-04 -7.74712724e-03\n",
      " -1.87474750e-01 -2.33454399e-01 -7.53633013e+00 -6.92893055e+00\n",
      " -1.60002142e-02 -5.96156029e-02 -9.48097886e+00 -4.74849457e-03\n",
      " -3.20088689e+00 -2.91900519e-02 -2.29614689e-02 -5.23134401e+00\n",
      " -2.91900519e-02 -2.02647472e-02 -8.38700831e+00 -3.79000849e+00\n",
      " -2.34438732e-01 -5.23134401e+00 -5.35230095e+00 -2.29614689e-02\n",
      " -5.96156029e-02 -3.21126423e-01 -2.90534710e-04 -6.83501775e-04\n",
      " -5.38596560e-03 -1.11130669e-03 -9.86899325e-03 -3.29019372e-02\n",
      " -6.08008294e-03 -1.11376530e-02 -4.17712182e-02 -3.31532678e-03\n",
      " -5.38596560e-03 -3.20088689e+00 -4.86898677e+00 -6.80748798e+00\n",
      " -8.63009738e+00 -6.08008294e-03 -2.93637741e-03 -2.02710420e-04\n",
      " -5.95798652e+00 -3.20088689e+00 -9.35941960e+00 -6.70689010e-02\n",
      " -2.29614689e-02 -5.96156029e-02 -8.23064658e-03 -5.29181323e+00\n",
      " -7.90087448e+00 -2.29614689e-02 -2.55458055e-05 -6.05154593e-03\n",
      " -2.58915245e-02 -4.72438971e-04 -5.36067771e-03 -2.29614689e-02\n",
      " -9.82276004e-03 -8.74421195e-03]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n",
      "loss:[-0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718 -0.69314718\n",
      " -0.69314718 -0.69314718]\t\n"
     ]
    }
   ],
   "source": [
    "# Call  LogisticRegression function and store weights in model.\n",
    "NumberOfIterations=1000\n",
    "LearningRate=0.1\n",
    "model = LogisticRegression(X_train,y_train,NumberOfIterations,LearningRate)\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on testing data. Store predictions in preds variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Store predictions in preds variable.\n",
    "threshold = 0.5\n",
    "preds = predict(X_test,threshold,model)\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy on test dataset given y_test (in the beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-9c6124fafaca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "total=0\n",
    "for i,j in y_test,preds:\n",
    "    total+=1\n",
    "    if(i==j):\n",
    "        count+=1\n",
    "\n",
    "Accuracy = (count*100)/total\n",
    "Accuracy\n",
    "\n",
    "# 1 Mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the reason behind such low accuracy? What do you think are possible ways of improving it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Marks for answering above question. Type out the answer below.\n",
    "The reason for such a low accuracy is that we have discarded most of the attributes without suitable exploration of \n",
    "how it is correlated with the predication value,i.e.,'Survived' feature. Moreover due to discarding all the null values, \n",
    "our dataset has shrunk to almost one-third. So instead of dropping those values, we should have replaced it with suitable \n",
    "values rather than plainly discarding it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type Here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROC Curve for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 5 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
